{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction to Convolutional Neural Networks**\n",
    "\n",
    "### [Matteo De Matola](https://github.com/matteo-d-m) \n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vigji/python-cimec-2024/blob/main/lectures/Lecture3.3_ConvNets.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural networks (CNNs) are a class of artificial neural networks that are widely used across several domains.\n",
    "\n",
    "In the last ten years, they have been increasingly used in neuroscience as:\n",
    "- Models of the ventral visual stream \n",
    "- EEG classifiers\n",
    "- MRI classifiers \n",
    "- EEG forecasters\n",
    "- & more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to their increasing popularity in neuroscientific research, it is increasingly important to understand what CNNs are and how to implement them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook cannot provide a throrough treatment of CNNs' theory and applications, nor can it be mathematically rigorous. But it will:\n",
    "\n",
    "- Provide all the basic definitions \n",
    "- Introduce all the essential Python tools\n",
    "- Build a working CNN for object recognition, step-by-step\n",
    "- Provide pointers to external resources (e.g., papers, books, and online courses) to deepen your understanding of CNN theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Table of Contents** <a class=\"anchor\" id=\"back-to-top\"></a>\n",
    "\n",
    "[Part 1: The Concepts](#part-1-the-concepts)\n",
    "- [Core Concept 1: Artificial Neural Networks](#first-concept)\n",
    "\n",
    "    - [1.1. The Artificial Neuron](#11-the-artificial-neuron)\n",
    "    \n",
    "        - [1.1.1. The Activation Function](#111-the-activation-function)\n",
    "    - [1.2. From Neuron to Network](#12-from-neuron-to-network)\n",
    "    - [1.3. From Network to Deep Network](#13-from-network-to-deep-network)\n",
    "- [Core Concept 2: From (Deep) Network to (Deep) Convolutional Network](#second-concept)\n",
    "    - [2.1. The Problem of Bidimensional Inputs](#21-the-problem-of-bidimensional-inputs)\n",
    "    - [2.2. Convolution Captures Local Structures](#22-convolution-captures-local-structures)\n",
    "- [Core Concept 3: Error-Driven Learning](#core-concept-3-error-driven-learning)\n",
    "    \n",
    "    - [3.0. Weights Shape Everything](#30-weights-shape-everything)\n",
    "    - [3.1. What is Error-Driven Learning?](#31-what-is-error-driven-learning)\n",
    "    - [3.2. The Rules of Error-Driven Learning](#32-the-rules-of-error-driven-learning)\n",
    "    - [3.3. The Prerequisites for Error-Driven Learning](#33-the-prerequisites-for-error-driven-learning)\n",
    "    - [3.4. Error Backpropagation](#34-error-backpropagation)\n",
    "    - [3.5. Training, Validation, and Testing](#35-training-validation-and-testing)\n",
    "\n",
    "[Part 2: The Implementation](#part-2-the-implementation)\n",
    "- [Enter: PyTorch](#enter-pytorch)\n",
    "- [Tensors, Datasets, and DataLoaders](#tensors-datasets--dataloaders)\n",
    "- [Building a CNN](#building-a-cnn)\n",
    "- [Model Selection, a.k.a. Hyperparameter Tuning](#model-selection-aka-hyperparameter-tuning)\n",
    "- [The Training-Validation Loop](#the-training-validation-loop)\n",
    "- [Finally: The Test](#finally-the-test)\n",
    "- [Inspecting a Trained Model: Basic Techniques](#inspecting-a-trained-model-basic-techniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part 1: The Concepts** <a class=\"anchor\" id=\"part-1-the-concepts\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if we don't go deep into the theory, there are three basic concepts that we must define before seeing the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Core Concept 1: Artificial Neural Networks** <a class=\"anchor\" id=\"first-concept\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, CNNs are a class of artificial neural networks (ANNs). \n",
    "\n",
    "ANNs are mathematical models of networks of interacting biological neurons. While their biological plausibility is debatable, ANNs have proven able to simulate some aspects of animal cognition, such as learning, vision, language, and executive control. \n",
    "\n",
    "Like their biological counterparts, ANNs have a functional unit: the artificial neuron.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1. The Artificial Neuron** <a class=\"anchor\" id=\"11-the-artificial-neuron\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The artificial neuron is the cornerstone of artificial neural networks. \n",
    "\n",
    "It is a mathematical model (basically, one equation) that represents a neuron as a weighted sum:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given: \n",
    "- $ \\vec{x} = [x_{1},x_{2},x_{3},...,x_{n}]  $ \n",
    "- $ \\vec{w} = [w_{1},w_{2},w_{3},...,w_{n}]  $ \n",
    "\n",
    "Calculate: \n",
    "\n",
    "$ \\displaystyle a = \\sum_{i = 1}^{n} w_{i}x_{i} = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + ... + w_{n}x_{n} $\n",
    "\n",
    "where\n",
    "\n",
    "- $ \\vec{x} $ = a vector that stores $ n $ input values\n",
    "- $ \\vec{w} $ = a vector that stores $ n $ corresponding weights\n",
    "- $ a = $ the neuron's activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is meant \n",
    "to model three biological facts:\n",
    "1. Real neurons receive **inputs** from multiple synapses\n",
    "2. Different synapses have different **strengths**, therefore, the corresponding inputs have different _weights_ (i.e., importance, salience, relevance...)\n",
    "3. Postsynaptic potentials (and _action_ potentials) are a **sum** of the local potentials generated by synaptic activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An artificial neuron may have a _bias_ term ($b$) to represent its baseline activity: \n",
    "\n",
    "$$ a = b + \\sum_{i = 1}^{n} w_{i}x_{i} = b + w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + ... + w_{n}x_{n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below implements an artificial neuron that receives a three-dimensional (random) input. \n",
    "\n",
    "In linear algebra jargon, the weighted sum of inputs is the _dot product_ between vector $\\vec{w}$ and vector $\\vec{x}$. This is why the corresponding NumPy function is called `dot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.random.seed(0)\n",
    "\n",
    "def artificial_neuron(inputs, weights, bias=0):\n",
    "    activation = bias + np.dot(inputs, weights) \n",
    "    return activation\n",
    "\n",
    "NUMBER_OF_INPUTS = 3\n",
    "inputs_vector = np.random.rand(1,NUMBER_OF_INPUTS)\n",
    "weights_vector = np.random.randn(NUMBER_OF_INPUTS,1)\n",
    "\n",
    "neuronal_activation = artificial_neuron(weights=weights_vector,\n",
    "                                        inputs=inputs_vector,\n",
    "                                        bias=0)\n",
    "\n",
    "print(f\"This neuron's activation is: {neuronal_activation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.1.1. The Activation Function** <a class=\"anchor\" id=\"111-the-activation-function\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computation of the neuron's activation value is usually followed by a nonlinear function that we call the _activation function_ ( $f$ ):\n",
    "\n",
    "$$ o = f(a) $$\n",
    "\n",
    "where\n",
    "\n",
    "- $o$ = the neuron's output\n",
    "- $a$ = the neuron's activation (weighted sum of its inputs)\n",
    "- $f$ = some nonlinear function\n",
    "\n",
    "The role of the activation function is to account (or at least, try to account) for the nonlinear nature of true neuronal activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ANNs literature contains a wealth of activation functions. One classic example is the sigmoid function:\n",
    "\n",
    "$$ \\sigma = \\frac{1}{(1+e^{-x})} $$\n",
    "\n",
    "While it might look complex, the sigmoid does little more than compressing the input between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid(x):\n",
    "    sigmoid = 1 / (1 + np.exp(-x))\n",
    "    return sigmoid\n",
    "\n",
    "input_values = np.array([n for n in range(-100,100)])\n",
    "sigmoid_values = sigmoid(x=input_values)\n",
    "plt.plot(input_values, sigmoid_values)\n",
    "plt.title(\"Sigmoid function\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid has been important in the past, but is not much used nowadays.\n",
    "\n",
    "A more modern activation function is the rectified linear unit (ReLU), which sets all negative values to zero and leaves all non-negative values as they were:\n",
    "\n",
    "$$\n",
    "ReLU(x) = \\begin{cases}\n",
    "                            x \\text{  if  } x \\geq 0 \\\\ \n",
    "                            0 \\text{  otherwise}\n",
    "                    \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    smaller_than_zero = (x <= 0)\n",
    "    relu_values = x.copy()              # because the next line works inplace\n",
    "    relu_values[smaller_than_zero] = 0    \n",
    "    return relu_values\n",
    "\n",
    "input_values = np.array([n for n in range(-100,100)])\n",
    "relu_values = relu(x=input_values)\n",
    "plt.plot(input_values, relu_values)\n",
    "plt.title(\"Rectified Linear Unit (ReLU)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you think about it, ReLU actually picks the maximum among 0 and $ x $. Therefore, it is more compactly written as:\n",
    "\n",
    "$$ ReLU(x) = max(0,x) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "input_values = np.array([n for n in range(-100,100)])\n",
    "relu_values = relu(x=input_values)\n",
    "plt.plot(input_values, relu_values)\n",
    "plt.title(\"Rectified Linear Unit (ReLU) - More compact, same result\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the effect of sigmoid and ReLU functions on a neuron's activation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_sigmoid_activation = sigmoid(neuronal_activation)\n",
    "with_relu_activation = relu(neuronal_activation)\n",
    "\n",
    "print(f\"Neuron's activation value (before any nonlinearity): {neuronal_activation} | After sigmoid: {with_sigmoid_activation}\") \n",
    "print(f\"Neuron's activation value (before any nonlinearity): {neuronal_activation} | After ReLU: {with_relu_activation}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interim Summary: The Artificial Neuron in a Nutshell**\n",
    "\n",
    "- The artificial neuron is a mathematical model of the biological neuron\n",
    "- Akin to the biological neuron, it receives multiple inputs. Different inputs have different weights (a.k.a. importance, salience, relevance...)\n",
    "- The artificial neuron is a weighted sum of inputs. It literally **IS** that\n",
    "- To account for the nonlinear behaviour of biological neurons, we feed the activations of artificial neurons into nonlinear functions\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./files/artificial-neuron.png\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2. From Neuron to Network** <a class=\"anchor\" id=\"12-from-neuron-to-network\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So... To model a single neuron, we multiply two vectors ($\\vec{w}$ and $\\vec{x}$):\n",
    "- One vector contains input data ($\\vec{x}$)\n",
    "- One vector contains the corresponding weights ($\\vec{w}$)\n",
    "\n",
    "To model a larger set of neurons (i.e., a network), we must multiply the vector of inputs ($\\vec{x}$) for a whole _matrix_ of weights ($W$). This matrix will have:\n",
    "\n",
    "- One row for each neuron in the network\n",
    "- One column for each input\n",
    "\n",
    "This really won't change anything but the number of neurons involved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given:\n",
    "\n",
    "- $ \\vec{x} = [x_{1},x_{2},x_{3},...,x_{n}]  $\n",
    "\n",
    "- $ W = \\displaystyle \\begin{bmatrix}\n",
    "                      w_{11} & w_{12} & w_{13} & ... &  w_{1n} \\\\\n",
    "                      w_{21} & w_{22} & w_{23} & ... &  w_{2n} \\\\\n",
    "                      w_{31} & w_{32} & w_{33} & ... &  w_{3n} \\\\\n",
    "                      \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "                      w_{m1} & w_{m2} & w_{m3} & ... & w_{mn} \n",
    "                      \\end{bmatrix}    $  \n",
    "\n",
    "Calculate: \n",
    "\n",
    "$ \\vec{a} = [a_{1},a_{2},a_{3},...,a_{m}]  $\n",
    "\n",
    "where\n",
    "\n",
    "- $ \\vec{x} = $ a vector that stores $ n $ input intensity values\n",
    "- $ W = $ a matrix that stores $ n $ corresponding weights for each of $ m $ neurons\n",
    "- $ \\vec{a} = $ a vector that stores $ m $ activation values (one for each neuron)\n",
    "\n",
    "Each element of $ \\vec{a} $ is the dot product (weighted sum) between $ \\vec{x} $ and one row of the weights matrix: \n",
    "\n",
    "\n",
    "$ \\displaystyle a_{i} = \\sum_{j = 1}^{n} w_{ij}x_{i} = w_{i1}x_{1} + w_{i2}x_{2} + w_{i3}x_{3} + ... + w_{in}x_{n} $ \n",
    "\n",
    "where \n",
    "\n",
    "- $ a_i = $ the activation value of the $ i^{th} $ neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what all looks like in video:\n",
    "\n",
    "<video width=\"1000\" height=\"auto\" controls>\n",
    "  <source src=\"./files/mat-vec-mul.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's what it all looks like in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artificial_neural_network(inputs, weights, bias=0):\n",
    "    network_activation = bias + np.dot(inputs, weights) \n",
    "    return network_activation\n",
    "\n",
    "NUMBER_OF_INPUTS = 3\n",
    "NUMBER_OF_NEURONS = 3\n",
    "some_random_inputs = np.random.rand(1,NUMBER_OF_INPUTS)\n",
    "some_corresponding_weights = np.random.randn(NUMBER_OF_NEURONS,NUMBER_OF_INPUTS)\n",
    "\n",
    "network_activation = artificial_neural_network(inputs=some_random_inputs,\n",
    "                                               weights=some_corresponding_weights,\n",
    "                                               bias=0)\n",
    "with_sigmoid = sigmoid(network_activation)\n",
    "with_relu = relu(network_activation)\n",
    "\n",
    "print(f\"Network activation (before any nonlinearity): {network_activation} | After sigmoid: {with_sigmoid}\")\n",
    "print(f\"Network activation (before any nonlinearity): {network_activation} | After ReLU: {with_relu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interim summary: From Neuron to Network in a Nutshell**\n",
    "\n",
    "- An ANN is a mathematical model of a _network_ of neurons\n",
    "- An ANN is composed of _multiple_ artificial neurons (so-called _nodes_) \n",
    "    - Each neuron is a weighted sum of inputs followed by a nonlinear function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3. From Network to Deep Network** <a class=\"anchor\" id=\"13-from-network-to-deep-network\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The multiplication between a vector of inputs and a matrix of coefficients yields the activity of a set of neurons. This set of neurons is called a _network layer_.\n",
    "    - Analogy: a brain area\n",
    "\n",
    "- But, what if we have _multiple_ sets of neurons that communicate with each other?\n",
    "    - One brain area that sends signals to another area, that sends them to another one, that sends them to another one...\n",
    "\n",
    "- To simulate this situation, we just concatenate multiple layers\n",
    "    - The output of a set of neurons becomes the input to another one\n",
    "    - Eventually, the output from the whole network will be shaped by each layer's output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what it looks like in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_layer(inputs, weights, bias, activation_function):\n",
    "    layer_activation = bias + np.dot(inputs, weights) \n",
    "    return activation_function(layer_activation)\n",
    "\n",
    "NUMBER_OF_INPUTS = 3\n",
    "NUMBER_OF_NEURONS = 3\n",
    "\n",
    "input_vector = np.random.rand(1,NUMBER_OF_INPUTS)\n",
    "first_layer_weights = np.random.randn(NUMBER_OF_NEURONS,NUMBER_OF_INPUTS)\n",
    "second_layer_weights = np.random.randn(NUMBER_OF_NEURONS,NUMBER_OF_INPUTS)\n",
    "third_layer_weights = np.random.randn(NUMBER_OF_NEURONS,NUMBER_OF_INPUTS)\n",
    "\n",
    "first_layer_activation_sigmoid = network_layer(inputs=input_vector,\n",
    "                                               weights=first_layer_weights,\n",
    "                                               bias=0,\n",
    "                                               activation_function=sigmoid)\n",
    "first_layer_activation_relu = network_layer(inputs=input_vector,\n",
    "                                            weights=first_layer_weights,\n",
    "                                            bias=0,\n",
    "                                            activation_function=relu)\n",
    "print(f\"Layer 1's activation - With sigmoid: {first_layer_activation_sigmoid} | With ReLU: {first_layer_activation_relu}\")\n",
    "print(\" \")\n",
    "\n",
    "second_layer_activation_sigmoid = network_layer(inputs=first_layer_activation_sigmoid,\n",
    "                                                weights=second_layer_weights,\n",
    "                                                bias=0,\n",
    "                                                activation_function=sigmoid)\n",
    "second_layer_activation_relu = network_layer(inputs=first_layer_activation_relu,\n",
    "                                             weights=first_layer_weights,\n",
    "                                             bias=0,\n",
    "                                             activation_function=relu)\n",
    "print(f\"Layer 2's activation - With sigmoid: {second_layer_activation_sigmoid} | With ReLU: {first_layer_activation_relu}\")\n",
    "print(\" \")\n",
    "\n",
    "third_layer_activation_sigmoid = network_layer(inputs=second_layer_activation_sigmoid,\n",
    "                                               weights=second_layer_weights,\n",
    "                                               bias=0,\n",
    "                                               activation_function=sigmoid)\n",
    "third_layer_activation_relu = network_layer(inputs=second_layer_activation_relu,\n",
    "                                            weights=first_layer_weights,\n",
    "                                            bias=0,\n",
    "                                            activation_function=relu)\n",
    "print(f\"Layer 2's activation - With sigmoid: {third_layer_activation_sigmoid} | With ReLU: {third_layer_activation_relu}\")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interim summary: From Network to Deep Network in a Nutshell**\n",
    "\n",
    "- A deep network is a chain of layers\n",
    "    - Each layer's output is the input to the next\n",
    "    - The output from each layer contributes to the output from the whole network\n",
    "\n",
    "- Each layer is itself a chain of two operations:\n",
    "    - Multiplication between $W$ and $\\vec{x}$  \n",
    "    - A nonlinear activation function ( $f$ )\n",
    "\n",
    "[Back to top](#back-to-top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Core Concept 2: From (Deep) Network to (Deep) Convolutional Network** <a class=\"anchor\" id=\"second-concept\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.1. The Problem of Bidimensional Inputs** <a class=\"anchor\" id=\"21-the-problem-of-bidimensional-inputs\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described above, a standard neural network layer consists of:\n",
    "\n",
    "- Multiplication between $W$ (a weights matrix) and $\\vec{x}$ (a vector of data) \n",
    "- A nonlinear activation function ( $f$ )\n",
    "\n",
    "The output of such layer is $\\vec{a}$, a vector of neuronal activation values (one value for each neuron in the layer). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works well for vector inputs, i.e., things like:\n",
    "\n",
    "$$ \\vec{x} = [x_{1},x_{2},x_{3},...,x_{n}]  $$\n",
    "\n",
    "In practice, such inputs might be EEG data from a given electrode, in a given time window (one number per time point): \n",
    "\n",
    "$$ EEG \\ (\\mu V) = [0.1, 0.16, -0.1, ..., 0.24] $$\n",
    "\n",
    "or the mean rent in [Rovereto](https://en.wikipedia.org/wiki/Rovereto) districts at any given time (one number per district):\n",
    "\n",
    "$$ Rent \\ (â‚¬) = [450, 465, 480, ..., 510] $$\n",
    "\n",
    "or anything else that can be described by a one-dimensional array. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, what do we do with grid-like, two-dimensional inputs?\n",
    "\n",
    "For example, what do we do with EEG data from several electrodes?\n",
    "\n",
    " $$ EEG \\ (\\mu V) = \\begin{bmatrix}\n",
    "                    0.12 & 0.16 & -0.10  & ... &  0.24 \\\\\n",
    "                    0.17 & 0.23 & -0.21 & ... &  0.33 \\\\\n",
    "                    1.33 & 0.97 & -0.34 & ... &  0.26 \\\\\n",
    "                    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "                    1.01   & 1.41 & 1.27 & ... & -2.35 \n",
    "                    \\end{bmatrix}    $$  \n",
    "\n",
    "And, what do we do with an image (which is just a grid of colour - or luminance - values)?\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./files/birdie.jpg\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, grid-like inputs could be multiplied by a weights matrix, like their vector counterparts. \n",
    "\n",
    "Given:\n",
    "\n",
    " - $ X = \\displaystyle \\begin{bmatrix}\n",
    "                      x_{11} & x_{12} & x_{13} & ... &  x_{1m} \\\\\n",
    "                      x_{21} & x_{22} & x_{23} & ... &  x_{2m} \\\\\n",
    "                      x_{31} & x_{32} & x_{33} & ... &  x_{3m} \\\\\n",
    "                      \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "                      x_{n1} & x_{n2} & x_{n3} & ... & x_{nm} \n",
    "                      \\end{bmatrix}    $ \n",
    "\n",
    "- $ W = \\displaystyle \\begin{bmatrix}\n",
    "                      w_{11} & w_{12} & w_{13} & ... &  w_{1n} \\\\\n",
    "                      w_{21} & w_{22} & w_{23} & ... &  w_{2n} \\\\\n",
    "                      w_{31} & w_{32} & w_{33} & ... &  w_{3n} \\\\\n",
    "                      \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "                      w_{m1} & w_{m2} & w_{m3} & ... & w_{mn} \n",
    "                      \\end{bmatrix}    $ \n",
    "\n",
    "We would calculate: \n",
    "\n",
    "- $ WX = A = \\displaystyle \\begin{bmatrix}\n",
    "                            a_{11} & a_{12} & a_{13} & ... &  a_{1m} \\\\\n",
    "                            a_{21} & a_{22} & a_{23} & ... &  a_{2m} \\\\\n",
    "                            a_{31} & a_{32} & a_{33} & ... &  a_{3m} \\\\\n",
    "                            \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "                            a_{m1} & a_{m2} & a_{m3} & ... & a_{mm} \n",
    "                            \\end{bmatrix}    $  \n",
    "\n",
    "\n",
    "Each element of $ A $ would be the dot product (weighted sum) between one row of $ W $ and one column of $ X $: \n",
    "\n",
    "\n",
    "$ \\displaystyle a_{ij} = \\sum_{j = 1}^{n} w_{ij}x_{ji} = w_{i1}x_{1j} + w_{i2}x_{2j} + w_{i3}x_{3j} + ... + w_{in}x_{nj} $ \n",
    "\n",
    "where \n",
    "\n",
    "- $ a_{ij} = $ is the response of the $ i^{th} $ neuron to the $ j^{th} $ column of the input matrix \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While feasible in principle, this would be:\n",
    "\n",
    "- Quite complex  \n",
    "  - If you tried it out with paper and pencil, you might have a hard time wrapping your mind around it\n",
    "\n",
    "- Lacking a straightforward interpretation  \n",
    "\n",
    "- Very inefficient\n",
    "    - It neglects the compositional structure of inputs\n",
    "    \n",
    "      - Wait - what is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2. Convolution Captures Local Structures** <a class=\"anchor\" id=\"22-convolution-captures-local-structures\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, grid-like inputs are a composition of local structures, or _**features**_:\n",
    "\n",
    "- An image is composed of edges, circles, and other geometric primitives\n",
    "- An EEG is composed of different patterns of activity from different electrodes\n",
    "- etc.\n",
    "\n",
    "To capture this local structure, we can:\n",
    "\n",
    "- Take a small weights matrix (smaller than the input) \n",
    "- Overlay this small weights matrix to an equally small patch of input\n",
    "- Multiply the small weights matrix and the small patch of input element-wise\n",
    "- Sum all the element-wise products\n",
    "- Repeat on a different patch until the whole input is covered\n",
    "\n",
    "This operation is known as _**(discrete) convolution**_ and is equivalent to taking the dot product between a patch of input and a set of weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that:\n",
    "\n",
    "- Convolution returns weighted sums of inputs that are specific to a given input region, that is, that represent a specific _feature_\n",
    "- We can interpret the result of convolution in terms of sensory neurons and their receptive fields\n",
    "\n",
    "This is better explained in video (the numbers are completely random):\n",
    "\n",
    "<video width=\"1000\" height=\"auto\" controls>\n",
    "  <source src=\"./files/discrete-conv.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding convolution requires to know three terms and understand their meaning:\n",
    "\n",
    "1. **Kernel:** the weights matrix. It's also called _filter_\n",
    "    - These terms are inherited from the fields of image and signal processing, where convolution is very popular\n",
    "\n",
    "2. **Padding:** a frame of zeros around the image. If the size of your kernel is such that the kernel might end up outside the input, you must pad the input with zeros - otherwise, Python will throw an error. This has no impact on the result, as the element-wise products of kernel values and padding values will be 0 \n",
    "\n",
    "3. **Stride:** the size of each kernel's step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the jargon, we can implement a convolution in pure NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height, input_width = 10, 10\n",
    "gridlike_input = np.random.rand(input_height,input_width)\n",
    "\n",
    "kernel_height, kernel_width = 2, 2\n",
    "convolution_kernel = np.random.randn(kernel_height,kernel_width)\n",
    "\n",
    "padding = 0\n",
    "horizontal_stride, vertical_stride = kernel_width, kernel_height\n",
    "\n",
    "output_height = int((input_height + 2*padding - kernel_height) / vertical_stride) + 1   # law\n",
    "output_width = int((input_width + 2*padding - kernel_width) / horizontal_stride) + 1    # law\n",
    "feature_map = np.zeros((output_height,output_width))\n",
    "\n",
    "width_covered, height_covered, convolution_steps  = 0, 0, 0\n",
    "for row in range(output_height):\n",
    "    for column in range(output_width):\n",
    "        input_patch = gridlike_input[height_covered:kernel_height+height_covered,\n",
    "                                     width_covered:kernel_width+width_covered]\n",
    "        feature_map[row,column] = np.sum(input_patch*convolution_kernel)\n",
    "        width_covered += horizontal_stride\n",
    "        convolution_steps += 1\n",
    "        print(f\"Feature map after {convolution_steps} convolution steps:\")\n",
    "        print(feature_map)\n",
    "        print(\" \")\n",
    "    width_covered = 0\n",
    "    height_covered += vertical_stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolution of a grid-like input with a kernel makes a _convolutional layer_. \n",
    "\n",
    "As it happens for standard network layers, the outputs of convolutional layers are fed into an activation function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Convolutional layer's output:\")\n",
    "print(feature_map)\n",
    "print(\" \")\n",
    "print(\"After sigmoid:\")\n",
    "print(sigmoid(feature_map))\n",
    "print(\" \")\n",
    "print(\"After ReLU:\")\n",
    "print(relu(feature_map))\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as it happens with standard network layers, convolutional layers can be concatenated into a deep network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#back-to-top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Core Concept 3: Error-Driven Learning** <a class=\"anchor\" id=\"core-concept-3-error-driven-learning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.0. Weights Shape Everything** <a class=\"anchor\" id=\"30-weights-shape-everything\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So... Every layer in a network takes in something and transforms it into something else. The exact shape of this transformation depends on the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_weights = np.random.randn(NUMBER_OF_NEURONS,NUMBER_OF_INPUTS)\n",
    "some_other_weights = np.random.randn(NUMBER_OF_NEURONS,NUMBER_OF_INPUTS)\n",
    "\n",
    "activation_with_some_weights = network_layer(inputs=input_vector,\n",
    "                                             weights=some_weights,\n",
    "                                             bias=0,\n",
    "                                             activation_function=sigmoid)\n",
    "activation_with_some_other_weights = network_layer(inputs=input_vector,\n",
    "                                                   weights=some_other_weights,\n",
    "                                                   bias=0,\n",
    "                                                   activation_function=sigmoid)\n",
    "\n",
    "plt.plot(activation_with_some_weights.T, \n",
    "         marker=\"o\",\n",
    "         label=\"with some weights\");\n",
    "plt.plot(activation_with_some_other_weights.T, \n",
    "         marker=\"o\",\n",
    "         label=\"with some other weights\");\n",
    "plt.title(\"Same data x different weights = different activations\");\n",
    "plt.xticks(ticks=[0,1,2],\n",
    "           labels=[\"Neuron 1\", \"Neuron 2\", \"Neuron 3\"]);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We face two related facts:\n",
    "\n",
    "1. An ANN's output is shaped by the weights\n",
    "    - When weights change, so does the output\n",
    "2. If you want a network to produce a given output, you need to change the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These facts create a problem: how can you change the weights towards a desired outputs?\n",
    "- You do _**error driven learning**_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1. What is Error-Driven Learning?** <a class=\"anchor\" id=\"31-what-is-error-driven-learning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error-driven learning is a simple algorithm (i.e., a sequence of actions):\n",
    "\n",
    "1. Feed your data into the ANN\n",
    "2. Compare the output to a target (i.e., a desired output)\n",
    "3. Calculate the error\n",
    "3. Change the weights \n",
    "4. Repeat until the error tends to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2. The Rules of Error-Driven Learning** <a class=\"anchor\" id=\"32-the-rules-of-error-driven-learning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work, error-driven learning must obey three rules:\n",
    "\n",
    "1. Weights must change in a way that minimises the error\n",
    "\n",
    "2. Different weights must change differently\n",
    "    - Because some contribute to the error more than others\n",
    "    \n",
    "3. Weights cannot change at random\n",
    "    - Otherwise, learning might take forever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.3. The Prerequisites for Error-Driven Learning** <a class=\"anchor\" id=\"33-the-prerequisites-for-error-driven-learning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In light of its rules, error-driven learning needs:\n",
    "\n",
    "1. An error function (a.k.a. _loss_ function)\n",
    "    - To compute the distance between real and desired output\n",
    "\n",
    "2. A [derivative](https://en.wikipedia.org/wiki/Derivative) of the error function with respect to the weights\n",
    "    - To quantify the contribution of each weight to the error function  \n",
    "    \n",
    "3. A rule to change weights appropriately\n",
    "    - Often, that's error backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.4. Error Backpropagation** <a class=\"anchor\" id=\"34-error-backpropagation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error backpropagation is the most basic and most common rule to change weights. \n",
    "\n",
    "In error backpropagation, we subtract from each weight a small fraction of its contribution to the error: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ w_i \\leftarrow w_i - \\alpha \\frac{\\delta L_{\\vec{w}}}{\\delta w_i} $$\n",
    "\n",
    "where\n",
    "\n",
    "- $ w_i = $ any given weight\n",
    "\n",
    "- $ \\alpha = $ the _learning rate_, i.e., an arbitrary coefficient between 0 and 1\n",
    "\n",
    "- $ \\displaystyle \\frac{\\delta L_{\\vec{w}}}{\\delta w_i} = $ the derivative of loss function $ L $ with respect to $ w_i $\n",
    "    - That's a measure of $ w_i $'s contribution to $ L $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $ \\displaystyle \\frac{\\delta L_{\\vec{w}}}{\\delta w_i}  $ can be positive or negative\n",
    "\n",
    "- If it's positive, it means that the weight is increasing the error\n",
    "    - We don't like that weight and we decrease it  \n",
    "- If it's negative, it means that the weight is decreasing the error\n",
    "    - We like that weight and we increase it\n",
    "\n",
    "(the key to seeing these facts is that minus times plus equals minus, while minus times minus equals plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.5. Training, Validation, and Testing** <a class=\"anchor\" id=\"35-training-validation-and-testing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, we don't want an algorithm to produce a desired output _once_. We want it to produce the desired output _forever_. \n",
    "\n",
    "To produce a desired output in a stable fashion, an algorithm must acquire **strong** knowledge about a given domain\n",
    "- For example, learn to recognise an image as containing a cat, everytime there is cat \n",
    "\n",
    "Knowledge is strong when it's based on the intrinsic, defining features of the data. \n",
    "\n",
    "Strong knowledge is:\n",
    "- Robust to small, contextual changes of the data \n",
    "    - You must recognise a cat regardless of it being brown, black, or spotted\n",
    "- Based on the data of interest, not on spurious covariates\n",
    "    - You must recognise a cat because it's a cat, not because it's always close to a cup of milk. Otherwise, you won't recognise it when you see it without milk    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANNs, CNNs, and other [machine learning](https://en.wikipedia.org/wiki/Machine_learning) algorithms acquire strong knowledge when: \n",
    "\n",
    "- They are exposed to a **large** body of data \n",
    "    - The more you see, the more you learn\n",
    "- They are exposed to a **rich** body of data \n",
    "    - Not all cats are brown\n",
    "- They can generalise their knowledge\n",
    "    - You can't memorise all the cats in the world. But when you meet a new cat, you must recognise it as such"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To favour strong knowledge, a typical learning algorithm undergoes three phases:\n",
    "\n",
    "- **Training:** the algorithm does error-driven learning on a (hopefully large) body of data. Recall that _error-driven learning_ means:\n",
    "\n",
    "    1. Feed your data into the ANN\n",
    "    2. Compare the output to a target (i.e., a desired output)\n",
    "    3. Calculate the error\n",
    "    3. Change the weights \n",
    "    4. Repeat until the error tends to zero\n",
    "- **Validation:** every $ n $ training iterations, the algorithm is fed some previously unseen samples\n",
    "    - Weights are not changed\n",
    "    - This is just an online sanity check for the training process\n",
    "- **Testing:** at the end of the training/validation cycle, the algorithm is fed some more previously unseen samples\n",
    "    - Weights are not changed\n",
    "    - This is the moment of truth: has the algorithm acquired robust knowledge?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#back-to-top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part 2: The Implementation** <a class=\"anchor\" id=\"part-2-the-implementation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have seen toy examples of artificial neurons and ANN layers. \n",
    "\n",
    "Despite dealing with simplified scenarios, the code examples got more and more complex as we progressed through the lecture. \n",
    "- Think about the convolution example: complex-ish, no?\n",
    "- Imagine coding a full network, the backpropagation algorithm, and the whole training-validation-test cycle!\n",
    "\n",
    "To survive real-world scenarios, we need a codebase that abstracts away the details and let us focus on high-level choices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Enter: PyTorch** <a class=\"anchor\" id=\"enter-pytorch\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PyTorch](https://pytorch.org/) is a Python library to build, train, and test deep artificial neural networks\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c6/PyTorch_logo_black.svg\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like many other Python libraries, PyTorch is:\n",
    "- Free\n",
    "- Open source\n",
    "- The result of a large-scale collaborative effort\n",
    "\n",
    "If you use PyTorch in published work, remember to cite the authors:\n",
    "\n",
    "[Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., ... & Chintala, S. (2019). PyTorch: An Imperative Style, High-Performance Deep Learning Library. _Advances in Neural Information Processing Systems_, 32](https://proceedings.neurips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html)\n",
    "\n",
    "The more we reward open source efforts, the more we liberate research from market rules!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch contains classes and functions to: \n",
    "\n",
    "- Download and use publicly available datasets \n",
    "- Set up any kind of ANN architecture\n",
    "- Train ANNs with a variety of learning algorithms\n",
    "- Exploit the parallel computing capabilities of graphics processing units (GPUs), which accelerate computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is fully compatible with the Python scientific computing ecosystem - in particular, it is well-integrated with NumPy. \n",
    "\n",
    "You can install PyTorch via `conda` or `pip`, following the instructions on the [PyTorch homepage](https://pytorch.org/). But it's probably faster to get started on Colab - especially because your computer is probably not powerful enough for deep learning. \n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vigji/python-cimec-2024/blob/main/lectures/Lecture3.3_ConvNets.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once installed (or, once opened this notebook in Colab), you can start using PyTorch with a simple import statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tensors, Datasets, & DataLoaders** <a class=\"anchor\" id=\"tensors-datasets--dataloaders\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will use PyTorch to build a CNN for image recognition. Therefore, we will need some images to work with. \n",
    "\n",
    "PyTorch has a companion library that contains classes and functions to work with images. This companion library is called `torchvision`.\n",
    "\n",
    "Among other things, `torchvision` contains a `datasets` package (a package is a collection of `.py` files), which provides tools to download and use publicly available image datasets. \n",
    "\n",
    "We will use the [MNIST dataset of handwritten digits](https://en.wikipedia.org/wiki/MNIST_database), which contains $70000$ handwriting samples of the numbers from $0$ to $9$, encoded as $28$ x $28$ grids of grayscale luminosity values:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./files/mnist-samples.png\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below downloads MNIST from its online repository. We do two separate downloads for the training and test datasets, assigning each to a separate variable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "training_dataset = torchvision.datasets.MNIST(root=\"classifier data\", \n",
    "                                              train=True, \n",
    "                                              download=True, \n",
    "                                              transform=transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"classifier data\", \n",
    "                                          train=False, \n",
    "                                          download=True, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables that we created are _dataset objects_. A dataset object implements two crucially important methods:\n",
    "\n",
    "- `__len__()`, which allows users to get the dataset's length\n",
    "- `__getitem__()`, which allows users to index into the dataset\n",
    "\n",
    "The double underscore before and after the two methods' names tells us that those methods are default. This means that we don't call them explicitly, but they work under the hood when we call `len(dataset)` and `dataset[index]`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's leverage `__len__()` to check how many samples we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_length = len(training_dataset)\n",
    "test_dataset_length = len(test_dataset)\n",
    "\n",
    "print(f\"The training dataset contains {training_dataset_length} samples, while the test dataset contains {test_dataset_length}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! Now let's leverage `__getitem__()` to inspect those samples and see what they look like. \n",
    "\n",
    "We will use one training sample as case study, but everything will apply equally to test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_training_sample = training_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extracted one sample from the training dataset. But, what type of data structure is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(one_training_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, each sample is a tuple. How many elements are contained in it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(one_training_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two items in each tuple! What are those items?\n",
    "\n",
    "- The first item is an image\n",
    "- The second item is a label that communicates the content of the image\n",
    "\n",
    "To make things clearer, let's [unpack the tuple](https://realpython.com/python-tuple/#packing-and-unpacking-tuples) and assign each of its items to a separate variable with an explanatory name.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = one_training_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's delve a bit deeper into both variables, starting from the label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"This sample's label is: {label}. Its datatype is: {type(label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the image contains a 5. Its label is a number (indeed, $5$) that's encoded as an `int`.  \n",
    "\n",
    "But, how is the image encoded? In other words, what type of data structure is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image is encoded as a PyTorch tensor! \n",
    "\n",
    "A tensor is basically an array with an arbitrary number of dimensions: while a vector has 1 dimension and a matrix has 2, a tensor can have any. \n",
    "\n",
    "PyTorch tensors are the same as NumPy arrays, except that:\n",
    "- They can be loaded into GPUs\n",
    "- They are optimised for fast and automatic [differentiation](https://www.britannica.com/science/differentiation-mathematics) of the functions that they represent (which is useful for backpropagation) \n",
    "\n",
    "These facts will make increasing sense as we proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like NumPy arrays, PyTorch tensors have a `.shape` attribute. When you access it, you get a variable of type `torch.Size` with information about the the tensor's shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of our image tensor is: {image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the shape is $1$ x $28$ x $28$. This means that the tensor contains an image with $1$ channel and  $28$ x $28$ shape. \n",
    "\n",
    " $1$ channel means one _colour_ channel - in other words, the image is black and white (more on this later).\n",
    "\n",
    " But, let's see our image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(image.squeeze(), cmap=\"gray\"); # the `.squeeze()` method suppresses the singleton dimension, allowing 2d plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not beautiful ($28$ x $28$ is low resolution), but it's a 5!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what's in our dataset, we can use it the way we want. \n",
    "\n",
    "We will start by reserving a random $25$% of the training dataset for validation. \n",
    "\n",
    "To this end, we will use the function `random_split()` from the `data` module (contained in the `utils` package and `data` module of the PyTorch library):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "use_for_training = int(len(training_dataset)*0.75)\n",
    "use_for_validation = int(len(training_dataset)*0.25)\n",
    "\n",
    "training_data, validation_data = random_split(dataset=training_dataset,\n",
    "                                              lengths=[use_for_training, use_for_validation],\n",
    "                                              generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "print(f\"The training dataset now contains {len(training_data)} samples, while the validation dataset contains {len(validation_data)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interim summary**\n",
    "\n",
    "- There is a Python library called PyTorch\n",
    "- PyTorch has a companion library called `torchvision`, which contains computer vision utilities\n",
    "    - `torchvision` contains a package called `datasets`, which provides access to a number of freely downloadable image datasets\n",
    "- Once downloaded and assigned to a variable, each dataset becomes a `Dataset` object\n",
    "    - `Dataset` objects have a length\n",
    "    - `Dataset` objects can be indexed to access specific samples\n",
    "- Each sample in a `Dataset` object is a tuple that contains: \n",
    "    - One image\n",
    "    - One label \n",
    "    \n",
    "    (at least, this is true of object recognition datasets)\n",
    "- Labels are encoded as `int`s, while images are encoded as Pytorch `tensor`s\n",
    "- We can slice `Dataset` objects with PyTorch functions such as `random_split()`\n",
    "- A PyTorch `tensor` is a pumped-up NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `Dataset` objects can be iterated over. For example, we can do things like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_number in range(10):\n",
    "    print(f\"Sample number {sample_number+1} is a tuple of {len(training_dataset[sample_number])} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, `Dataset` objects behave like standard iterables - that is, they can only retrieve one sample at a time. But when you train an ANN, you want to access multiple samples at once and process them as if they were a single tensor. This is known as **batch** (or _minibatch_) **processing**, and it can increase training speed. \n",
    "\n",
    "In real-world scenarios, you also want to fully exploit your machine's power and to shuffle training samples at every iteration. \n",
    "\n",
    "To achieve this, you need a `DataLoader` object. A `DataLoader` object takes a `Dataset` object and empowers it with: \n",
    "\n",
    "- Batch processing capabilities (i.e., process batches of samples as if they were a single tensor)\n",
    "- Multiprocessing capabilities (i.e., use all your machine's power to access as much data as possible in parallel)\n",
    "- Shuffling capabilities (i.e., access samples in a different order everytime, to avoid order effects on the learning process)\n",
    "\n",
    "We will now create  one `DataLoader` object for each of our `Dataset` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "training_loader = DataLoader(dataset=training_data,\n",
    "                             batch_size=15000,\n",
    "                             shuffle=True,\n",
    "                             num_workers=2,\n",
    "                             pin_memory=True)\n",
    "\n",
    "validation_loader = DataLoader(dataset=validation_data,\n",
    "                               batch_size=len(validation_data),\n",
    "                               shuffle=False,\n",
    "                               num_workers=2,\n",
    "                               pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=len(test_dataset),\n",
    "                         shuffle=False,\n",
    "                         num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike `Dataset` objects, `DataLoader` objects cannot be indexed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_loader[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, they can be iterated over. \n",
    "\n",
    "Therefore, to inspect the content of a dataloder we need to run a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in training_loader:\n",
    "    \"\"\"Just print out the type, length (where applicable), and shape (where applicable) of each sample\"\"\"\n",
    "    print(type(sample), \",\", len(sample), \"|\",  type(sample[0]), \",\",  sample[0].shape, \"|\",  type(sample[1]), \",\",  sample[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see three important things:\n",
    "\n",
    "- The `DataLoader` object contains three samples (one per batch)\n",
    "\n",
    "- Each item is a list of two elements:\n",
    "\n",
    "    - The first element is a tensor of shape `(batch_size, n_channels, image_height, image_width)`. It contains a batch of images\n",
    "\n",
    "    - The second element is a tensor of shape `(batch_size)`. It contains a batch of labels\n",
    "\n",
    "During training, we will feed data to the CNN as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in training_loader:\n",
    "    # CNN processes batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, the CNN will process each batch as a whole, as if it were a single image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Building a CNN** <a class=\"anchor\" id=\"building-a-cnn\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data and an efficient way to access them, we can feed them to a CNN. \n",
    "\n",
    "But first, we need a CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, neural networks are represented as [classes](https://github.com/vigji/python-cimec-2024/blob/main/lectures/Lecture0.5_define_classes.ipynb). \n",
    "\n",
    "This makes sense if you think that:\n",
    "\n",
    "- A neural network has certain structural components, which are its layers. These components will be the _attributes_ of the neural network class\n",
    "- A neural network does certain things, like transforming the data. These things will be the _methods_ of the neural network class \n",
    "\n",
    "Whenever you code a neural network in PyTorch, you need to write a class. This class **must** inherit from the base class `Module`, which is contained in a PyTorch module called `nn` (yes, they put something called `Module` inside a module. Not helpful...).\n",
    "\n",
    "The following code implements a convolutional neural network with two convolutional layers followed by two standard, non-convolutional layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "  \"\"\"A convolutional neural network\"\"\"\n",
    "\n",
    "  def __init__(self, dropout_probability):                                              \n",
    "    super().__init__() \n",
    "    self.conv1 = nn.Conv2d(in_channels=1, \n",
    "                           out_channels=20, \n",
    "                           kernel_size=5, \n",
    "                           stride=2)\n",
    "    self.conv2 = nn.Conv2d(in_channels=20,\n",
    "                           out_channels=20,\n",
    "                           kernel_size=5,\n",
    "                           stride=2)\n",
    "    self.flatten = nn.Flatten(start_dim=1) \n",
    "    self.standard1 = nn.Linear(in_features=4*4*20, \n",
    "                               out_features=125) \n",
    "    self.standard2 = nn.Linear(in_features=125,\n",
    "                               out_features=10)\n",
    "    self.dropout = nn.Dropout(p=dropout_probability)\n",
    "    self.activation_function = nn.ReLU()\n",
    "\n",
    "  def forward(self, layer_input):\n",
    "    layer_input = self.activation_function(self.conv1(layer_input))\n",
    "    layer_input = self.activation_function(self.conv2(layer_input))\n",
    "    layer_input = self.flatten(layer_input)        \n",
    "    layer_input = self.activation_function(self.standard1(layer_input))\n",
    "    layer_input = self.activation_function(self.dropout(layer_input))\n",
    "    final_output = self.standard2(layer_input)\n",
    "    return final_output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code contains some terms that you know, like:\n",
    "\n",
    "- Kernel\n",
    "- Stride\n",
    "- Activation function\n",
    "\n",
    "And other terms that you don't know. Let's define them, one by one:\n",
    "\n",
    "- **Input channels (`in_channels`):** the inputs to a convolution can be elementary (like our black-and-white images), or they can result from the combination of multiple sub-inputs (like colour images, which are a combination of a Red, a Green, and a Blue image - RGB). When the input is elementary, the convolution is said to have one _input channel_. But when the input is a combination of multiple sub-inputs, the convolution is said to have _multiple_ input channels. If our input images were coloured, the convolution would have 3 input channels (one for R, one for G, and for B). In case of multiple input channels, the convolution kernel operates over each channel and the results are summed element-wise into one single feature map. But we don't care about that for now, because our inputs have a single channel (they are black and white)\n",
    "\n",
    "- **Output channels (`out_channels`):** the number of feature maps that the convolution layer should produce. Note that to produce $n$ feature maps, we need $n$ kernels - therefore, setting the number of output channels is equivalent to setting the number of kernels that we want to use. Using multiple kernels increases the chances of building strong knowledge of the input (see below for a more detailed explanation)\n",
    "\n",
    "- **Flatten (`nn.Flatten`):** after using multiple kernels, we want to collapse all corresponding feature maps into a single vector to feed to the standard layers. To do so, we reshape each feature map into a one-dimensional tensor (i.e., we _flatten_ it) and we concatenate the result into one big vector. This is done by the `Flatten` class contained in PyTorch's `nn` package\n",
    "\n",
    "- **Linear (`nn.Linear`):** just a synonym for _standard neural network layer_, emphasizing that the layer implements a linear transformation of the input. Other synonyms that you might find are _fully connected_ and _dense_, which both emphasize how all elements of the input contribute to each element of the output (in contrast to convolutional layers, where each input patch gives rise to a well-defined portion of the feature map due to the local nature of convolutions)\n",
    "\n",
    "- **Input features (`in_features`)  & Output features (`out_features`):** how many elements are contained in the input & output vectors of the linear layer. Note that: \n",
    "\n",
    "    - The input features are constrained by the size of the input tensor - be it data or the output of a previous layer. In our case, we have `in_features = 4*4*20` because the second convolutional layer outputs 20 feature maps, each of which is $4$ x $4$. This means that after flattening, we have a vector with $4$ x $4$ x $20$ = $320$ elements\n",
    "    - The output features are arbitrary\n",
    "\n",
    "- **Dropout (`nn.Dropout`):** this is a special type of layer that turns randomly selected weights into $0$, with a given probability ([Srivastava et al., 2014](https://www.jmlr.org/papers/v15/srivastava14a.html)). While relatively obscure from the theoretical standpoint, dropout is proven to improve learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Optional: Why Using Multiple Kernels Per Layer?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quote below is _verbatim_ from my own master's thesis, [_A Study of Spiking Neural Networks for Biologically Plausible Deep Learning_](https://thesis.unipd.it/handle/20.500.12608/3104).\n",
    "\n",
    "[TL;DR](https://en.wikipedia.org/wiki/TL%3BDR): using multiple kernels increases the chances of getting a good one\n",
    "\n",
    "_\"Having to choose the number of kernels (as well as their size) might seem like\n",
    "a useless complication. In fact, one might as well use a single kernel. But there\n",
    "are at least two reasons why it is useful to have multiple kernels, the first of\n",
    "which is neuroscientific. [...] each kernel produces a feature\n",
    "map for output. From a neuroscientific standpoint, every such feature map is\n",
    "an activity pattern over H x W neurons â€“ that is, a neuronal representation of\n",
    "the input. Using multiple kernels generates multiple such representations,\n",
    "simulating distributed processing in the brain (the more the kernels, the more\n",
    "distributed the processing). The second argument in favour of multiple kernels\n",
    "is more technical, and it has to do with the actual kernel-generation process. \n",
    "[...] convolution kernels are initialized at random [...] their initial values constrain learning\n",
    "dynamics by setting a starting point to their evolutionary path. Some starting\n",
    "points may be better than others, i.e., may be such that a smaller number of\n",
    "weight updates is required for the network to converge to optimal performance.\n",
    "In this sense, using multiple kernels increases the probability of setting an\n",
    "optimal start to the learning process, and the more the kernels, the higher such\n",
    "probability\"._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Selection, a.k.a. Hyperparameter Tuning** <a class=\"anchor\" id=\"model-selection-aka-hyperparameter-tuning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the data, an efficient way to access them, and a CNN to process them. At this point, we could start training the CNN.\n",
    "\n",
    "However, training a neural network is a complex process that's influenced by a myriad factors - for example:\n",
    "\n",
    "- The size of layers\n",
    "\n",
    "- The number of layers\n",
    "\n",
    "- The dropout probability\n",
    "\n",
    "- The rule to update weights (there are many flavours of backpropagation)\n",
    "\n",
    "- The value of the constants in the weights update rule\n",
    "    - The most important is the  _learning rate_, that is, the $ \\alpha $ in $ \\displaystyle w_i \\leftarrow w_i - \\alpha \\frac{\\delta L_{\\vec{w}}}{\\delta w_i} $ \n",
    "        - Remember: $ 0 < \\alpha < 1 $\n",
    "\n",
    "- and countless others..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These factors are known as _**hyperparameters**_ (to distinguish them from the _parameters_, which are the network's weights).\n",
    "\n",
    "Each possible combination of hyperparameters defines a different neural network with different learning potential. Therefore, picking the right combination is vital.\n",
    "\n",
    "To pick the right combination, we just try out different combinations for a small number of training-validation iterations, then pick the one with the most promising results.\n",
    "\n",
    "- This process is known as _**model selection**_ or _**hyperparameter tuning**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the space of possible sets is infinite. How do we select the sets to try? \n",
    "\n",
    "We have at least two options:\n",
    "\n",
    "1. **Random search:** pick random hyperparameter values (or sets of values)\n",
    "\n",
    "2. **Grid search:** define the hyperparameter values (or sets of values) manually, on the basis of previous knowledge about what might or might not work\n",
    "\n",
    "\n",
    "We'll make the example with a grid search.\n",
    "\n",
    "The code below defines a function to construct combinations of hyperparameter values from a dictionary, then uses it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "\n",
    "def combine(hyperparameters):\n",
    "  \"\"\"Constructs combinations of hyperparameter values.\n",
    "\n",
    "  Parameters:\n",
    "  hyperparameters -- map between hyperparameter names and candidate values (dict[list])\n",
    "\n",
    "  Returns:\n",
    "  candidates -- combinations of hyperparameters values (list[namedtuple])\n",
    "  \"\"\"\n",
    "\n",
    "  candidate = namedtuple(\"combination\", hyperparameters.keys()) \n",
    "  candidates = []\n",
    "  for combination in product(*hyperparameters.values()): \n",
    "    candidates.append(candidate(*combination))\n",
    "  return candidates\n",
    "\n",
    "hyperparameter_values_to_try = dict(dropout_probability=[0.25, 0.5],\n",
    "                                    learning_rate=[1e-2, 1e-3, 1e-4],\n",
    "                                    weight_decay=[1e-4, 1e-5])  \n",
    "\n",
    "hyperparameter_combinations = combine(hyperparameter_values_to_try)\n",
    "\n",
    "print(f\"We will try the following {len(hyperparameter_combinations)} hyperparameter combinations:\")\n",
    "print(\" \")\n",
    "for index, combination in enumerate(hyperparameter_combinations):\n",
    "  print(f\"{index+1}:\", combination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our combinations of hyperparameter values, we need to use them. \n",
    "\n",
    "Specifically, we need code to:\n",
    "\n",
    "1. Run a given number of training-validation cycles, for each combination\n",
    "2. Select the combination that yields the best result (i.e., the least validation loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below runs a certain number of training-validation cycles (or _epochs_, in machine learning jargon):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim \n",
    "\n",
    "def train_and_validate(model, device, combination, epochs, dataloaders):\n",
    "  \"\"\"Performs model training and validation.\n",
    "  \n",
    "  Parameters:\n",
    "  model -- a PyTorch model instance\n",
    "  device -- where to run computations (torch device object)\n",
    "  combination -- a combination of hyperparameter values (namedtuple)\n",
    "  epochs -- number of model runs (int)\n",
    "  dataloaders -- PyTorch dataloader instances (tuple)\n",
    "  \"\"\"\n",
    "\n",
    "  cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(model.parameters(), \n",
    "                         lr=combination.learning_rate,\n",
    "                         weight_decay=combination.weight_decay)\n",
    "  training_loss_log = []\n",
    "  validation_loss_log = []\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    training_loss = []\n",
    "    model.train()\n",
    "    for batch in dataloaders[0]:\n",
    "      image = batch[0].to(device)\n",
    "      label = batch[1].to(device)\n",
    "      output = model(image)\n",
    "      loss = cross_entropy_loss(output, label)\n",
    "      model.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      loss = loss.detach().cpu().numpy()\n",
    "      training_loss.append(loss)\n",
    "    validation_loss = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for batch in dataloaders[1]:\n",
    "        image = batch[0].to(device)\n",
    "        label = batch[1].to(device)\n",
    "        output = model(image)\n",
    "        loss = cross_entropy_loss(output, label)\n",
    "        loss = loss.detach().cpu().numpy()\n",
    "        validation_loss.append(loss)\n",
    "    training_loss = np.mean(training_loss)\n",
    "    training_loss_log.append(training_loss)\n",
    "    validation_loss = np.mean(validation_loss)\n",
    "    validation_loss_log.append(validation_loss)\n",
    "    print(f\"EPOCH {epoch+1} - TRAINING LOSS: {training_loss: .2f} - VALIDATION LOSS: {validation_loss: .2f}\")\n",
    "    if epoch == epochs-1:\n",
    "      print(\"Finished\")\n",
    "  torch.save(model.state_dict(), 'model_parameters.torch')\n",
    "  return training_loss_log, validation_loss_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... And the function below runs training-validation cycles for each combination of hyperparameter values, then picks the best one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(combinations, device, dataloaders):\n",
    "  \"\"\"Chooses the best combination of hyperparameters.\n",
    "  \n",
    "  Parameters:\n",
    "  combinations -- hyperparameter combinations to evaluate (namedtuple)\n",
    "  device -- where to run computations (torch device object)\n",
    "  dataloaders -- PyTorch dataloader instances (tuple)\n",
    "  \"\"\"\n",
    "\n",
    "  scores = []\n",
    "  for combination in combinations:\n",
    "    model = CNN(dropout_probability=combination.dropout_probability)\n",
    "    model.to(device)\n",
    "    print(f\"Combination {combinations.index(combination)+1} of {len(combinations)}\")\n",
    "    score = train_and_validate(model=model, \n",
    "                               device=device, \n",
    "                               combination=combination, \n",
    "                               epochs=10, \n",
    "                               dataloaders=dataloaders) \n",
    "    scores.append(score)\n",
    "  print(\"Model selection finished!\")\n",
    "  training_scores = []\n",
    "  validation_scores = []\n",
    "  for score in scores:\n",
    "    training, validation = score\n",
    "    training_scores.append(training)\n",
    "    validation_scores.append(validation)\n",
    "  least_validation_score = min(validation_scores)\n",
    "  idx = validation_scores.index(least_validation_score)\n",
    "  winner = combinations[idx]\n",
    "  return winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the functions, we can put them to work!\n",
    "\n",
    "Note that we run all computations on the GPU (`torch.device(\"cuda\")`) if possible, and on the CPU if it's not (`torch.device(\"CPU\")`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"CPU\")\n",
    "print(f\"Device is: {device}\")\n",
    "\n",
    "optimal_hyperparameters = hyperparameter_tuning(combinations=hyperparameter_combinations,\n",
    "                                                device=device,\n",
    "                                                dataloaders=(training_loader, validation_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The winning hyperparameter combination is: {optimal_hyperparameters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The Training-Validation Loop** <a class=\"anchor\" id=\"the-training-validation-loop\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a winning combination of hyperparameter values, we can use them for the actual training-validation cycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "model = CNN(dropout_probability=optimal_hyperparameters.dropout_probability)\n",
    "model.to(device)\n",
    "\n",
    "losses = train_and_validate(model=model,\n",
    "                            device=device,\n",
    "                            combination=optimal_hyperparameters,\n",
    "                            epochs=50,\n",
    "                            dataloaders=(training_loader, validation_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quickest way to inspect the results of training is to plot the loss trend over training epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(size, losses, labels):\n",
    "  \"\"\"Draws line plots of losses (i.e., model errors) vs. epoch number.\n",
    "  \n",
    "  Parameters:\n",
    "  size -- figsize (tuple)\n",
    "  losses -- the losses to draw (list)\n",
    "  labels -- the graph's labels (list)\n",
    "  \"\"\"\n",
    "\n",
    "  plt.figure(figsize=(size[0],size[1]))\n",
    "  plt.semilogy(losses[0], label=labels[0])\n",
    "  plt.semilogy(losses[1], label=labels[1])\n",
    "  plt.title(\"Loss over epochs\")\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Loss\")\n",
    "  plt.legend()\n",
    "  plt.grid()\n",
    "  plt.show()\n",
    "\n",
    "plot_losses(size=(12,8),\n",
    "            losses=losses,\n",
    "            labels=[\"Training loss\", \"Validation loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, both the training and validation loss decayed exponentially over training epochs. \n",
    "\n",
    "Curiously, the validation loss was systematically lower than the training loss for the first 22/23 epochs, then it stopped decreasing while the training loss kept going down.\n",
    "\n",
    "This is a twofold phenomenon that opens the door to some keys issues in ANNs learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Point 1: The validation loss was lower than the training loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming no bugs, this can be due to various reasons. Among them:\n",
    "\n",
    "1. The training process is subject to **regularisation**, while the validation process is not. This means that training is intentionally underpowered to prevent the ANN from [overfitting](https://en.wikipedia.org/wiki/Overfitting) - that is, finding weights that are too specific to training data and would not work on validation or test data (we used dropout and weight decay as regularisation techniques). As a result, the performance on the training data is a bit worse than the network's true potential \n",
    "\n",
    "2. The validation dataset contains easier samples than the training dataset. As the two datasets are created with a random split of one father dataset, this is possible (note that _possible_ doesn't mean _likely_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Point 2: The validation loss stopped decreasing, while the training loss kept decreasing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the network started to overfit (around epoch 22/23). We could have stopped training at that point, and test performance would have not changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Finally: The Test** <a class=\"anchor\" id=\"finally-the-test\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below tests the trained network on previously unseen samples (i.e., the test dataset). \n",
    "\n",
    "It's basically the same as previous code for training-validation, with the difference that we calculate accuracy as a performance metric (more interpretable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, dataloader):\n",
    "  \"\"\"Evaluates the model on novel samples.\n",
    "  \n",
    "  Parameters:\n",
    "  model -- a PyTorch model instance\n",
    "  device -- where to run computations (torch device object)\n",
    "  dataloader -- a PyTorch dataloader instance\n",
    "  \"\"\"\n",
    "\n",
    "  images = []\n",
    "  labels = []\n",
    "  predictions = []\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for sample in dataloader:\n",
    "      image = sample[0].to(device)\n",
    "      label = sample[1].to(device)\n",
    "      pred = model(image)\n",
    "      images.append(image)\n",
    "      labels.append(label)\n",
    "      predictions.append(pred)\n",
    "  images = torch.cat(images)\n",
    "  labels = torch.cat(labels)\n",
    "  predictions = torch.cat(predictions)\n",
    "  correct = predictions.argmax(dim=1).eq(labels).sum()\n",
    "  accuracy = correct*100/len(labels)\n",
    "  print(f\"TEST ACCURACY: {accuracy: .2f}%\")\n",
    "  return predictions\n",
    "\n",
    "test_outputs = test(model=model,\n",
    "                    device=device,\n",
    "                    dataloader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Inspecting a Trained Model: Basic Techniques** <a class=\"anchor\" id=\"inspecting-a-trained-model-basic-techniques\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once trained and tested a network, you might want to characterise its behaviour. \n",
    "\n",
    "In particular, you might want to understand what input features drive its performance, or what classes are easier vs. harder to discriminate.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the many techniques to characterise a model's behaviour, a confusion matrix is perhaps the simplest. \n",
    "\n",
    "This is simply a matrix that stores the number of corrects vs. incorrect responses for each class in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as sklearn_confusion\n",
    "\n",
    "def plot_confusion_matrix(true, predicted, classes):\n",
    "  \"\"\"Plots a heatmap-style confusion matrix. \n",
    "\n",
    "  Parameters:\n",
    "  true -- ground truth labels (array-like)\n",
    "  predicted -- labels predicted by the model (array-like)\n",
    "  classes -- the number of classes in the dataset (int)\n",
    "  \"\"\"\n",
    "  \n",
    "  matrix = sklearn_confusion(true, predicted)\n",
    "  plt.figure(figsize=(12,10))\n",
    "  plt.imshow(matrix, interpolation = 'nearest', cmap ='Reds')\n",
    "  matrix_cells = product(range(matrix.shape[0]), range(matrix.shape[1]))\n",
    "  for row_index, column_index in matrix_cells:\n",
    "    plt.text(x=row_index, \n",
    "             y=column_index, \n",
    "             s=matrix[row_index][column_index],\n",
    "             horizontalalignment=\"center\",\n",
    "             verticalalignment=\"center\",\n",
    "             color=\"white\" if row_index == column_index else \"black\")\n",
    "  ticks = np.arange(classes)\n",
    "  plt.xticks(ticks)\n",
    "  plt.yticks(ticks)\n",
    "  plt.xlabel(\"Predicted label\")\n",
    "  plt.ylabel(\"True label\")\n",
    "  plt.title(\"Test confusion matrix\")\n",
    "  plt.colorbar()\n",
    "  return matrix\n",
    "\n",
    "\n",
    "true_image_labels = test_dataset.targets.cpu().numpy()\n",
    "predicted_image_labels = torch.argmax(input=test_outputs,dim=1).cpu().numpy()\n",
    "\n",
    "confusion_matrix = plot_confusion_matrix(true=true_image_labels,\n",
    "                                         predicted=predicted_image_labels,\n",
    "                                         classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While interesting, the confusion matrix is not explicit about which classes are easier vs. harder to learn. \n",
    "\n",
    "To obtain this information, we can count the number of mistakes per class and plot them with a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_incorrect(dataset, confusion_matrix, classes):\n",
    "  \"\"\"Creates a bar chart of test mistakes per class.\n",
    "  \n",
    "  Parameters:\n",
    "  dataset -- a PyTorch dataset\n",
    "  confusion_matrix -- a confusion matrix (2darray)\n",
    "  classes -- the number of classes in the dataset (int)\n",
    "  \"\"\"\n",
    "\n",
    "  bins = dataset.targets.bincount()\n",
    "  incorrect = [bins[i] - confusion_matrix[i][i] for i in range(len(bins))] \n",
    "  bars = np.arange(classes) \n",
    "  plt.figure(figsize=(12,8))\n",
    "  plt.bar(bars, incorrect)\n",
    "  plt.xticks(bars)\n",
    "  plt.xlabel(\"Class label\")\n",
    "  plt.ylabel(\"Incorrectly classified samples\")\n",
    "  plt.title(\"Number of mistakes per class\")\n",
    "  plt.grid(axis=\"y\")\n",
    "\n",
    "plot_incorrect(dataset=test_dataset,\n",
    "               confusion_matrix=confusion_matrix,\n",
    "               classes=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#back-to-top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Moving Forward: Exercises**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have covered quite a lot of material! \n",
    "\n",
    "I intentionally left out practicals because I wanted enough time to convey the basic concepts. If you still want to tinker with CNNs, you can: \n",
    "\n",
    "1. Play around with the hyperparameters:\n",
    "\n",
    "    - What happens without dropout? \n",
    "    - What happens without weight decay?\n",
    "    - What happens with a different learning rate?\n",
    "    - What happens with smaller/larger convolution kernels?\n",
    "    - What happens with convolution strides larger than one?\n",
    "    - What happens with more/less convolutional/linear layers?\n",
    "2. Try a random search instead of our grid search\n",
    "3. Play around with my code: make changes, watch them break the code, understand why they do\n",
    "4. Use a different dataset: `torchvision` [contains many](https://pytorch.org/vision/stable/datasets.html)\n",
    "    - Are the current hyperparameters fit for a new dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Moving Forward: Readings & Tutorials**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the neuroscientific community, the machine learning community is incredibly prone to open science. \n",
    "\n",
    "The Internet is full of high-quality readings and tutorials - many of which have a non-academic approach (and are great nonethelss). \n",
    "\n",
    "While it's impossible to collect all pointers here, I can list a few essentials (all of which have been made freely available by the authors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Machine/Deep Learning Concepts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One-stop shop for deep learning concepts. Academic book. Provides a thorough treatment of almost everything there is to know. [Link](https://www.deeplearningbook.org/)\n",
    "\n",
    "- Good Coursera course by leading expert Andrew Ng. [Link](https://www.coursera.org/learn/neural-networks-deep-learning)\n",
    "    - And another one about training strategies. [Link](https://www.coursera.org/learn/deep-neural-network#modules)\n",
    "\n",
    "- Stanford course on convolutional neural networks. [Link](https://cs231n.stanford.edu/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mathematical Background**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Old lecture notes by Mark van Rossum, then at University of Edinburgh. Clear and concise. Chapters 1-5 are relevant (but ignore paragraphs 4.2 and 4.4). [Link](https://www.inf.ed.ac.uk/teaching/courses/fmcs1/lecture_notes/lecture_notes_neural.pdf)\n",
    "\n",
    "- Video introductions to linear algebra. Non-academic, incredibly high quality. Contain more than necessary. [Link](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)\n",
    "\n",
    "- Video introductions to calculus. Non-academic, incredibly high quality. Contain more than necessary. [Link](https://www.youtube.com/playlist?list=PL0-GT3co4r2wlh6UHTUeQsrf3mlS2lk6x)\n",
    "\n",
    "- One-stop shop for machine learning mathematics. Academic book. [Link](https://mml-book.github.io/)\n",
    "    - There is an associated Coursera learning path. [Link](https://www.coursera.org/specializations/mathematics-machine-learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
